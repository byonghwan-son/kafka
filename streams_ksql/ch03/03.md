# 상태가 없는 처리

* 레코드 필터링
* 필드 추가 및 삭제
* 레코드의 키 변경(rekeying)
* 스트림 가지치기(branching)
* 스트림 병합(merging)
* 레코드를 하나 또는 그 이상의 출력으로 변환
* 레코드를 한 번에 하나씩 보강(enrich)

## 상태가 없는 처리 vs 상태가 있는 처리

* 상태가 없는 애플리케이션에서 카프카 스트림즈 애플리케이션이 처리한 각 이벤트는 다른 이벤트와 독립적으로 처리. 애플리케이션은 각 이벤트를 독립적인 삽입(INSERT)으로 간주하고 이전에 처리한 이벤트에 대해서는 어떠한 기억도 안함.
* 상태가 있는 애플리케이션에서는 프로세서 토폴로지의 한 두 단계 이상의 이전 단계에서 처리했던 이벤트에 대한 정보를 기억. 상태가 있는 처리는 보통 집계, 윈도잉 또는 이벤트 스트림들을 조인할 목적으로 사용. 내부적인 처리가 훨씬 복잡함.

filter 연산자 : 무상태  
count 연산자 : 상태  

### 튜토리얼 소개 : 트위터 스트림 처리

![트윗을 보강하는 애플리케이션이 구현할 토폴로지](../img/2023-11-12%2013%2034%2007.png)

### 프로젝트 설치

[git 참조](https://github.com/mitch-seymour/mastering-kafka-streams-and-ksqldb/tree/master/chapter-03/crypto-sentiment)

### KStream 소스 프로세서 추가

하나 이상의 소스 토픽으로부터 데이터를 소비함  
[tweets]라는 토픽  
트위터 소스 커넥터를 이용해 트위터의 Streaming API를 사용해 트윗을 읽고 JSON으로 인코딩.

```java
StreamBuilder builder = new StreamBuilder();

// byte[] 타입의 매개변수 : 빠른 처리 속도
// Key : byte[], Value : byte[]
KStream<byte[], byte[]> stream = builder.stream("tweets");
```

카프카 스트림즈 애플리케이션을 포함해 카프카 클라이언트가 상위 수준의 객체와 문자열, JSON, Avro, ProtoBuf등과 같은 포맷으로 작업하려면 이 바이트 스트림을 직렬과하고 역직렬화하는 책임을 클라이언트가 갖고 있다는 것을 의미

카프카 스트림즈 토폴로지 구축을 실제 애플리케이션 실행 코드와 분리

### 직렬화 / 역직렬화

```java
// CryptoTopology.java
package com.example;

import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.Printed;

class CryptoTopology {
    public static Topology build() {
        StreamBuilder builder = new StreamBuilder();

        KStream<byte[], byte[]> stream = builder.stream("tweets");
        stream.print(Printed.<byte[], byte[]>toSysOut().withLabel("tweets-stream"));

        return builder.build();
    }
}
```

```java
/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package com.example;

import java.util.Properties;

import org.apache.kafka.clients.consumer.ConsumerConfig;
// import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.Topology;

public class App {
    public static void main(String[] args) {
        Topology topology = CryptoTopology.build();

        Properties config = new Properties();
        config.put(StreamsConfig.APPLICATION_ID_CONFIG, "dev");
        config.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:29092");
        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        // config.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Void().getClass());
        // config.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        KafkaStreams streams = new KafkaStreams(topology, config);

        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));

        System.out.println("Starting Twitter streams...");

        streams.start();
    }
}
```

![직렬화와 역직렬화의 차이](../img/2023-11-13%2020%2029%2031.png)

#### 커스텀 Serdes 만들기

Gson(<https://github.com/google/gson>)

bytes 배열을 객체로 변환  

```java
Gson gson = new Gson();
byte[] bytes = ...;
Type type = ...;
gson.fromJson(new String(bytes), type);
```

객체를 bytes 배열로 변환

```java
Gson gson = new Gson();
gson.toJson(instance).getBytes(StarndardCharsets.UTF_8);
```
