# 카프카 스트림즈 시작하기

* Producer API
* Consumer API
* Connect API

데이터가 도착하자마자 즉시 처리하고 반응하기

* 초기 스트림 처리 애플리케이션 구축
  * Consumer와 Producer API를 직접 사용
  * 별도 스트림 처리 프레임워크 사용(Apache Spark Streaming, Apache Flink) 
  * 부족한 요소
    * 로컬 내결함성 상태
    * 데이터 스트림을 변환할 다양한 연산자들
    * 고급 스트림 표현
    * 정교한 시간 처리
  * 결국 이 부족한 요소가 Kafka Stream의 장점이 됨.

![카프카 스트림즈](../img/2023-11-11%2013%2031%2055.png)

* 특징
  * 상위 수준의 DSL
  * 하위 수준의 Processor API
  * 스트림, 테이블과 같은 데이터 모델링 추상화
  * 스트림과 테이블의 조인 기능
  * 다양한 연산자와 도구들
  * 시간-기반 연산 지원(윈도우, 주기 함수)
  * 쉬운 설치
  * 운영 특성 : 확장성, 신뢰성, 유지보수성

* 운영 특성
  * 확장성(Scalability)
  * 신뢰성(Reliablity)
  * 유지 보수성(Maintainability)

* 처리 모델
  * 한 번에 한 이벤트(카프카)와 마이크로-배치 처리(그 외)

* 카파 아키텍처
  * 스트림-관계형(Stream-Relational) 처리 플랫폼 vs 아파치 빔은 스트림 전용(Stream-Only) 처리 플랫폼
  * 관계(또는 테이블)은 일급 시민(first-class citizens). 각 관계는 독립적인 정체성을 가짐
  * 관계는 다른 관계로 변환 가능
  * 임의로 관계를 쿼리할 수 있음

* 실시간 의사 결정이나 데이터 처리
* 실시간 이벤트 스트림즈와 스트림 연산들(filtering, joining, windowing, data transform)
  * 스트림의 상태는 이벤트 스트림에서 집계(각 영상의 총 시청 수) 
  * 빠르게 변화하는 개체의 최신 상태

## 프로세스 토폴로지(처리 과정)

* DFP : Data Flow Programming
* DAG : Directed Acyclic Graph (방향성 비순환 그래프)
![DAG](../img/2023-11-11%2021%2024%2037.png)
  * 소스 프로세스(Source Process)
    * 카프카 토픽으로부터 데이터를 읽고 하나 이상의 스트림 프로세스로 전송
  * 스트림 프로세스(Stream Process)
    * 데이터 처리/변환 로직
    * filter, map, flatMap ,join 등
  * 싱크 프로세스(Sink Process)
    * 보강, 변환, 필터링 등으로 처리한 레코드를 카프카로 다시 내보내는 역할
    * 다른 스트림 처리 애플리케이션, 카프카 커넥트
    * 카프카 토픽과 연결
* 서브 토폴로지
* 깊이-우선 처리
* DFP의 이점
  * 여러 스레드와 애플리케이션 인스턴스로 쉽게 생성되고 병렬화 할 수 있는 템플릿으로 동작
* 태스크와 스트림 스레드
* 추상화 수준
  * 상위-수준의 DSL
  * 하위-수준의 Processor API

```yml
# docker-compose.yml
---
version: '3'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:6.0.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "32181:32181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-enterprise-kafka:6.0.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:32181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

  kafka-create-topics:
    image: confluentinc/cp-enterprise-kafka:6.0.0
    depends_on:
      - kafka
    hostname: kafka-create-topics
    command: ["bash", "./create-topics.sh"]
    working_dir: /scripts
    volumes:
    - ./scripts:/scripts
```

```bash
# create-topics.bash
echo "Waiting for Kafka to come online..."

cub kafka-ready -b kafka:9092 1 20

# create the users topic
kafka-topics \
  --bootstrap-server kafka:9092 \
  --topic users \
  --replication-factor 1 \
  --partitions 4 \
  --create

sleep infinity
```

```bash
# scripts 디렉토리 생성 후에 create-topics.sh를 만들어야 햠.
# docker-compose.yml 파일이 있는 디렉토리로 이동 후 실행
$ docker-compose up
# .. 도커가 실행되면서 'users' topic까지 자동으로 생성됨.

# 도커 생성 확인
$ docker-compose exec kafka bash
# shell 변경
[appuser@kafka ~]$ kafka-topics --bootstrap-server localhost:9092 --list
users
# 빠져나오려면 Ctrl+d 혹은 exit 엔터키를 누른다.

$ mkdir my-project && cd my-proejct

$ gradle init \
    --type java-application \
    --dsl groovy \
    --test-framework junit-jupiter \
    --project-name my-project \
    --package com.example
```

build.gradle 파일 수정

```gradle
/*
 * This file was generated by the Gradle 'init' task.
 *
 * This generated file contains a sample Java application project to get you started.
 * For more details on building Java & JVM projects, please refer to https://docs.gradle.org/8.4/userguide/building_java_projects.html in the Gradle documentation.
 */

plugins {
    id 'java'
    id 'application'
}

repositories {
    jcenter()
}

dependencies {
    implementation 'org.apache.kafka:kafka-streams:2.7.0'
}

task runDSL(type: JavaExec) {
    main = "com.example.DslExample"
    classpath sourceSets.main.runtimeClasspath
}

task runProcessorAPI(type: JavaExec) {
    main = 'com.example.ProcessorApiExample'
    classpath sourceSets.main.runtimeClasspath
}
```

### DSL 과정

고도의 추상화처리가 되어 있음.

```java
// DslExample.java
package com.example;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KStream;

import java.util.Properties;

public class DslExample {
    public static void main(String[] args) {
        StreamsBuilder builder = new StreamsBuilder();

        KStream<Void, String> stream = builder.stream("users");

        stream.foreach((key, value) -> {
            System.out.println("(DSL) Hello, " + value);
        });

        Properties config = new Properties();
        config.put(StreamsConfig.APPLICATION_ID_CONFIG, "dev1");
        config.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:29092");
        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        config.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Void().getClass());
        config.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        KafkaStreams streams = new KafkaStreams(builder.build(), config);
        streams.start();

        // JVM이 중단될 때(SigTerm) 카프카 스트림즈를 닫는다.
        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
    }
}
```

실행하기

```bash
$ gradlew runDSL --info

> Task :app:run
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
(DSL) Hello, angie
(DSL) Hello, guy
(DSL) Hello, kate
(DSL) Hello, mark
```

```bash
$ docker-compose exec kafka bash

# bash 전환
[appuser@kafka ~]$ kafka-console-producer --bootstrap-server localhost:9092 --topic users
> angie
> guy
> kate
> mark
```

### Processor API

Topology.addSource, Topology.addProcessor, Topology.addSink를 직접 생성

```java
// ProcessorApiExample.java
package com.example;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.Topology;

import java.util.Properties;

public class ProcessorApiExample {
    public static void main(String[] args) {
        Topology topology = new Topology();

        topology.addSource("UserSource", "users");
        topology.addProcessor("SayHello", SayHelloProcessor::new, "UserSource");

        Properties config = new Properties();
        config.put(StreamsConfig.APPLICATION_ID_CONFIG, "dev2");
        config.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:29092");
        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        config.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Void().getClass());
        config.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        KafkaStreams streams = new KafkaStreams(topology, config);
        System.out.println("Starting streams");
        streams.start();

        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
    }
}
```

```java
// SayHelloProcessor.java
package com.example;

import org.apache.kafka.streams.processor.api.Processor;
import org.apache.kafka.streams.processor.api.ProcessorContext;
import org.apache.kafka.streams.processor.api.Record;

public class SayHelloProcessor implements Processor<Void, String, Void, Void> {

    @Override
    public void close() {

    }

    @Override
    public void init(ProcessorContext<Void, Void> context) {

    }

    @Override
    public void process(Record<Void, String> record) {
        System.out.println("(Processor API) Hello, " + record.value());        
    }
}
```

실행하기

```bash
$ gradlew runProcessorAPI --info
# ...
Starting streams
(Processor API) Hello, guy
(Processor API) Hello, kate
(Processor API) Hello, angie
(Processor API) Hello, mark
```

### 스트림과 테이블

* 스트림 : insert
* 테이블 : update
  * RocksDB를 사용해 구현한 키-값 저장소에 물리화(materialized)됨.

### 스트림/테이블 이중성

테이블은 스트림으로 표현 가능하고, 스트림은 테이블을 재구성하는데 사용  
테이블은 특정 시점의 스트림을 표현  
테이블은 새 레코드가 도착하면 관련 키와 값을 갱신  
테이블을 스트림으로 변경하면 갱신을 삽입으로 처리해 키와 값을 갱신하는 대신 새로운 레코드를 로그의 끝에 추가함  

```java
var stream = table.entrySet().stream().collect(Collectors.toList());

stream.add(Map.entry("a", 3));

// stream ==> [a=2, b=1, a=3]
```

### KStream, KTable, GlobalKTable

* KStream  
  파티셔닝된 레코드 스트림의 추상화  
  이 추상화 내의 데이터는 삽입(Insert) 시멘틱을 사용해 표현

* KTable  
  KTable은 파티셔닝된 테이블의 추상화(예 : 변경 로그 스트림)  
  이 추상화 내의 데이터는 갱신(Update) 시멘틱을 사용해 표현

* GlobalKTable  
  GlobalKTable은 데이터의 전체(예를 들어 파티셔닝되지 않은) 복사본을 포함하는 것만 제외하고 KTable과 비슷함.
